{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import sklearn\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import fbprophet\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "from plotly.subplots import make_subplots\n",
    "from pandas.plotting import lag_plot\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from source import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Importing the data\n",
    "The imported data below was created from a function that runs through each csv, creates a dataframe for each and then merges them.  Columns are converted to appropriate data types and any mismatches are fixed before merging.  This is important as Leeds City Council changed the formats of the files several times, which led to some differences in column names and potentially data types."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#import merged footfall data\n",
    "footfalldf_imported = pd.read_csv(\"../data/footfall_merged.csv.gz\",\n",
    "\t\t\t\t\t\t\t\t  parse_dates=['Date','DateTime'],\n",
    "\t\t\t\t\t\t\t\t  dtype={\"BRCYear\": int,\"BRCWeekNum\":int},\n",
    "\t\t\t\t\t\t\t\t  index_col=[0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cleaning the data\n",
    "The next step in the pipeline is to check for duplicates and remove them.  Initial data exploration revealed errors in some of the csv files where individual records had been duplicated.  In some instances, the same records existed in several different files, for example dates in early July appeared towards the end of the June csv.\n",
    "\n",
    "The cameras don't all come online at the same time, with the last starting on 27th August 2008.  To ensure meaningful comparability, any records before this date have been removed.\n",
    "\n",
    "Finally, one of the cameras appeared to have moved locations on 31st May 2015 from Commercial Street at Lush to Commercial Street at Sharps.  These are combined and renamed to Commercial Street Combined."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Footfall hasn't changed when combining cameras\n",
      "There are 0 duplicates left\n"
     ]
    }
   ],
   "source": [
    "#Pipeline that imports csv files, creates a dataframe and applies cleaning functions\n",
    "footfalldf = (footfalldf_imported\n",
    "\t\t\t  .pipe(start_pipeline)\n",
    "\t\t\t  .pipe(set_start_date, '2008-08-27')\n",
    "\t\t\t  .pipe(combine_cameras)\n",
    "\t\t\t  .pipe(check_remove_dup)\n",
    "\t\t\t  .pipe(remove_new_cameras)\n",
    "\t\t\t  .pipe(create_BRC_MonthNum))\n",
    "\n",
    "\n",
    "\n",
    "#Useful list for if months ever lost when resampling or plotting.\n",
    "Months = ['January','February','March','April','May','June','July','August','September','October','November','December']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Resample Data\n",
    "\n",
    "First resample dataframes to daily, weekly and monthly total footfall."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#Resample into daily footfall.\n",
    "day = footfalldf.groupby( [pd.Grouper(key='DateTime',freq='D')])['Count'].sum().to_frame()\n",
    "#dayfinal = pd.concat([day,frame],verify_integrity=True)\n",
    "day = day.drop(day[day['Count'] == 0].index)\n",
    "#Set frequency to daily, creating additional rows for missing values and impute using the 'time' based interpolation\n",
    "day = day.asfreq('D').dropna()#.replace(0,np.nan).interpolate(method='time')\n",
    "\n",
    "month = footfalldf.groupby( [pd.Grouper(key='DateTime',freq='M')])['Count'].sum().to_frame()\n",
    "month = month.drop(month[month['Count'] == 0].index)\n",
    "month = month.asfreq('M').dropna()#.replace(0,np.nan).interpolate(method='time')\n",
    "\n",
    "week = footfalldf.groupby( [pd.Grouper(key='DateTime',freq='W')])['Count'].sum().to_frame()\n",
    "week = week.drop(week[week['Count'] == 0].index)\n",
    "week = week.asfreq('W').dropna()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}